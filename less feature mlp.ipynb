{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11180\\3432705918.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeaturetarget\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'row_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'time_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"investment_id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcorr_matrix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeaturetarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorr_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"target\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "featuretarget= df.drop(['row_id', 'time_id', \"investment_id\"], axis=1)\n",
    "corr_matrix=featuretarget.corr()\n",
    "a=corr_matrix[\"target\"].sort_values()\n",
    "b=abs(a)\n",
    "c=b.sort_values()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f_276    0.014485\n",
       "f_236    0.014531\n",
       "f_152    0.014582\n",
       "f_298    0.014584\n",
       "f_22     0.014629\n",
       "           ...   \n",
       "f_280    0.046870\n",
       "f_265    0.047300\n",
       "f_119    0.049404\n",
       "f_250    0.055838\n",
       "f_231    0.062049\n",
       "Name: target, Length: 200, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[100:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('featureimportance',c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurename=list(c.index[100:300])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('less faetures mlp with little dropout/featureimportance',featurename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = df[featurename]\n",
    "y = df[\"target\"]\n",
    "id=df[\"investment_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "feature=torch.from_numpy(feature.values)\n",
    "id=torch.from_numpy(id.values)\n",
    "y=torch.from_numpy(y.values)\n",
    "class FinData(Dataset):\n",
    "    def __init__(self,feature,id,y):\n",
    "        self.feature = feature.squeeze().to(\"cuda\")\n",
    "        self.y = y.squeeze().to(\"cuda\")\n",
    "        self.id = id.squeeze().to(torch.int64).to(\"cuda\")\n",
    "        self.len = len(y)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return self.id[idx],self.feature[idx],self.y[idx]\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "Dataset_train=FinData(feature=feature,id=id,y=y)\n",
    "DataLoader1=DataLoader(Dataset_train,batch_size=128,shuffle=True)\n",
    "DataLoader2=DataLoader(Dataset_train,batch_size=1024,shuffle=True)\n",
    "DataLoader3=DataLoader(Dataset_train,batch_size=512,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.embedding=nn.Embedding(4000,32)\n",
    "        self.linear1=nn.Linear(32,64)\n",
    "        self.linear2=nn.Linear(64,64)\n",
    "        self.linear3=nn.Linear(200,256)\n",
    "        self.linear4=nn.Linear(256,256)\n",
    "        self.linear5=nn.Linear(320,512)\n",
    "        self.linear6=nn.Linear(512,128)\n",
    "        self.linear7=nn.Linear(128,32)\n",
    "        self.linear8=nn.Linear(32,1)\n",
    "        self.dropout=nn.Dropout(p=0.1)\n",
    "      \n",
    "\n",
    "    def forward(self, feature, id):\n",
    "        id=self.embedding(id).squeeze()\n",
    "        id=self.linear1(id).squeeze()\n",
    "        id=id*torch.sigmoid(id)\n",
    "        id=self.linear2(id).squeeze()\n",
    "        id=id*torch.sigmoid(id)\n",
    "        id=self.dropout(id)\n",
    "        id=self.linear2(id).squeeze()\n",
    "        id=id*torch.sigmoid(id)\n",
    "\n",
    "\n",
    "        feature=self.linear3(feature).squeeze()\n",
    "        feature=feature*torch.sigmoid(feature)\n",
    "        feature=self.linear4(feature).squeeze()\n",
    "        feature=feature*torch.sigmoid(feature)\n",
    "        feature=self.dropout(feature)\n",
    "        feature=self.linear4(feature).squeeze()\n",
    "        feature=feature*torch.sigmoid(feature)\n",
    "\n",
    "        x=torch.cat((id,feature),1)\n",
    "        x=self.linear5(x).squeeze()\n",
    "        x=x*torch.sigmoid(x)\n",
    "        x=self.linear6(x).squeeze()\n",
    "        x=x*torch.sigmoid(x)\n",
    "\n",
    "        x=self.linear7(x).squeeze()\n",
    "        x=self.dropout(x)\n",
    "        x=x*torch.sigmoid(x)\n",
    "\n",
    "        x=self.linear8(x).squeeze()\n",
    "        x=40*torch.sigmoid(x)-20\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_1 = NeuralNetwork().to(\"cuda\")\n",
    "model1_1=model1_1.double()\n",
    "model1_2 = NeuralNetwork().to(\"cuda\")\n",
    "model1_2=model1_2.double()\n",
    "\n",
    "model2_1 = NeuralNetwork().to(\"cuda\")\n",
    "model2_1=model2_1.double()\n",
    "model2_2 = NeuralNetwork().to(\"cuda\")\n",
    "model2_2=model2_2.double()\n",
    "\n",
    "\n",
    "model3_1 = NeuralNetwork().to(\"cuda\")\n",
    "model3_1=model3_1.double()\n",
    "model3_2 = NeuralNetwork().to(\"cuda\")\n",
    "model3_2=model3_2.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "optimizer1_1 = torch.optim.Adam(model1_1.parameters(), lr=learning_rate,weight_decay=1e-4)\n",
    "optimizer1_2 = torch.optim.Adam(model1_2.parameters(), lr=learning_rate,weight_decay=1e-3)\n",
    "optimizer2_1 = torch.optim.Adam(model2_1.parameters(), lr=learning_rate,weight_decay=1e-4)\n",
    "optimizer2_2 = torch.optim.Adam(model2_2.parameters(), lr=learning_rate,weight_decay=1e-3)\n",
    "optimizer3_1 = torch.optim.Adam(model3_1.parameters(), lr=learning_rate,weight_decay=1e-4)\n",
    "optimizer3_2 = torch.optim.Adam(model3_2.parameters(), lr=learning_rate,weight_decay=1e-3)\n",
    "loss_fn1=torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_1(dataloader, model, optimizer):\n",
    "    for  id,feature,y in tqdm(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(feature,id)\n",
    "        loss = loss_fn1(pred,y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "def train_2(dataloader, model, optimizer):\n",
    "    for id,feature, y in tqdm(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(feature,id)\n",
    "        loss = -torch.corrcoef(torch.stack((pred,y)))[0,1]\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24543/24543 [02:28<00:00, 165.74it/s]\n",
      "100%|██████████| 24543/24543 [02:50<00:00, 144.04it/s]\n",
      "100%|██████████| 3068/3068 [00:45<00:00, 66.92it/s]\n",
      "100%|██████████| 3068/3068 [00:53<00:00, 57.51it/s]\n",
      "100%|██████████| 6136/6136 [00:55<00:00, 110.61it/s]\n",
      "100%|██████████| 6136/6136 [01:06<00:00, 92.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24543/24543 [02:39<00:00, 153.87it/s]\n",
      "100%|██████████| 24543/24543 [03:11<00:00, 127.91it/s]\n",
      "100%|██████████| 3068/3068 [00:52<00:00, 58.50it/s]\n",
      "100%|██████████| 3068/3068 [01:05<00:00, 47.18it/s]\n",
      "100%|██████████| 6136/6136 [01:01<00:00, 100.04it/s]\n",
      "100%|██████████| 6136/6136 [01:15<00:00, 81.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24543/24543 [02:09<00:00, 190.02it/s]\n",
      "100%|██████████| 24543/24543 [02:31<00:00, 162.41it/s]\n",
      "100%|██████████| 3068/3068 [00:44<00:00, 69.67it/s]\n",
      "100%|██████████| 3068/3068 [00:49<00:00, 62.28it/s]\n",
      "100%|██████████| 6136/6136 [00:54<00:00, 113.28it/s]\n",
      "100%|██████████| 6136/6136 [01:00<00:00, 100.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24543/24543 [02:07<00:00, 192.00it/s]\n",
      "100%|██████████| 24543/24543 [02:31<00:00, 161.96it/s]\n",
      "100%|██████████| 3068/3068 [00:44<00:00, 69.57it/s]\n",
      "100%|██████████| 3068/3068 [00:49<00:00, 62.14it/s]\n",
      "100%|██████████| 6136/6136 [00:54<00:00, 113.16it/s]\n",
      "100%|██████████| 6136/6136 [01:01<00:00, 100.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24543/24543 [02:07<00:00, 191.94it/s]\n",
      "100%|██████████| 24543/24543 [02:31<00:00, 162.19it/s]\n",
      "100%|██████████| 3068/3068 [00:44<00:00, 69.69it/s]\n",
      "100%|██████████| 3068/3068 [00:49<00:00, 62.19it/s]\n",
      "100%|██████████| 6136/6136 [00:54<00:00, 113.00it/s]\n",
      "100%|██████████| 6136/6136 [01:01<00:00, 100.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24543/24543 [02:08<00:00, 191.73it/s]\n",
      "100%|██████████| 24543/24543 [02:46<00:00, 147.31it/s]\n",
      "100%|██████████| 3068/3068 [00:47<00:00, 64.23it/s]\n",
      "100%|██████████| 3068/3068 [00:55<00:00, 54.85it/s]\n",
      "100%|██████████| 6136/6136 [00:58<00:00, 105.64it/s]\n",
      "100%|██████████| 6136/6136 [01:08<00:00, 90.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24543/24543 [02:21<00:00, 173.06it/s]\n",
      "100%|██████████| 24543/24543 [02:48<00:00, 145.33it/s]\n",
      "100%|██████████| 3068/3068 [00:47<00:00, 64.36it/s]\n",
      "100%|██████████| 3068/3068 [00:56<00:00, 54.61it/s]\n",
      "100%|██████████| 6136/6136 [00:57<00:00, 106.09it/s]\n",
      "100%|██████████| 6136/6136 [01:08<00:00, 90.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24543/24543 [02:21<00:00, 173.21it/s]\n",
      "100%|██████████| 24543/24543 [02:49<00:00, 144.60it/s]\n",
      "100%|██████████| 3068/3068 [00:47<00:00, 64.18it/s]\n",
      "100%|██████████| 3068/3068 [00:56<00:00, 54.15it/s]\n",
      "100%|██████████| 6136/6136 [00:57<00:00, 106.03it/s]\n",
      "100%|██████████| 6136/6136 [01:08<00:00, 89.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24543/24543 [02:23<00:00, 171.33it/s]\n",
      "100%|██████████| 24543/24543 [02:49<00:00, 144.46it/s]\n",
      "100%|██████████| 3068/3068 [00:48<00:00, 63.79it/s]\n",
      "100%|██████████| 3068/3068 [00:56<00:00, 54.51it/s]\n",
      "100%|██████████| 6136/6136 [00:58<00:00, 105.72it/s]\n",
      "100%|██████████| 6136/6136 [01:08<00:00, 89.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24543/24543 [02:22<00:00, 172.14it/s]\n",
      "100%|██████████| 24543/24543 [02:50<00:00, 143.80it/s]\n",
      "100%|██████████| 3068/3068 [00:48<00:00, 62.61it/s]\n",
      "100%|██████████| 3068/3068 [00:56<00:00, 53.96it/s]\n",
      "100%|██████████| 6136/6136 [07:49<00:00, 13.08it/s]\n",
      "100%|██████████| 6136/6136 [15:49<00:00,  6.46it/s] \n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"epoch{}/{}\".format(i+1,10))\n",
    "    train_1(DataLoader1,model1_1,optimizer1_1)\n",
    "    train_2(DataLoader1,model1_2,optimizer1_2)\n",
    "    train_1(DataLoader2,model2_1,optimizer2_1)\n",
    "    train_2(DataLoader2,model2_2,optimizer2_2)\n",
    "    train_1(DataLoader3,model3_1,optimizer3_1)\n",
    "    train_2(DataLoader3,model3_2,optimizer3_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model1_1, 'less faetures mlp with little dropout/model1_1.pth')\n",
    "torch.save(model1_2, 'less faetures mlp with little dropout/model1_2.pth')\n",
    "torch.save(model2_1, 'less faetures mlp with little dropout/model2_1.pth')\n",
    "torch.save(model2_2, 'less faetures mlp with little dropout/model2_2.pth')\n",
    "torch.save(model3_1, 'less faetures mlp with little dropout/model3_1.pth')\n",
    "torch.save(model3_2, 'less faetures mlp with little dropout/model3_2.pth')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8d54f9552fa829e297b1fedb11353f4eeb32c8a885e3418c0be5f50c074ccfc7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
