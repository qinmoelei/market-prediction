{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3579"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.investment_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3773"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df.investment_id.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here is a little different. for the in the origional tensorflow. the data is made from the len+1 yet in the previous test it was made from max+1\n",
    "I do not think just use the len is a good idea for some of the data will only appear on the test set so i think it is a little unsafe.\n",
    "this experiment is based on the len instead of max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = df.drop(['row_id', 'time_id', 'target',\"investment_id\"], axis=1)\n",
    "id=df[\"investment_id\"]\n",
    "y=df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the orginal code actually uses mutiple models to do the predictions and decides to use PCA to get them all together\n",
    "the 3 models must share the same structure and the difference might lies on the loss function, optimiser and the train dataset.\n",
    "I am going to create 3 models: loss has 3 variants and we can do it in different batch size. \n",
    "\n",
    "FYI, poor ensemble learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "feature=torch.from_numpy(feature.values).to(device)\n",
    "id=torch.from_numpy(id.values).to(device)\n",
    "y=torch.from_numpy(y.values).to(device)\n",
    "class FinData(Dataset):\n",
    "    def __init__(self,feature,id,y):\n",
    "        self.feature = feature.squeeze().to(\"cuda\")\n",
    "        self.y = y.squeeze().to(\"cuda\")\n",
    "        self.id = id.squeeze().to(torch.int64).to(\"cuda\")\n",
    "        self.len = len(y)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return self.id[idx],self.feature[idx],self.y[idx]\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "Dataset_train=FinData(feature=feature,id=id,y=y)\n",
    "DataLoader1=DataLoader(Dataset_train,batch_size=256,shuffle=True)\n",
    "DataLoader2=DataLoader(Dataset_train,batch_size=1024,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.embedding=nn.Embedding(4000,32)\n",
    "        self.linear1=nn.Linear(32,64)\n",
    "        self.linear2=nn.Linear(64,64)\n",
    "        self.linear3=nn.Linear(300,256)\n",
    "        self.linear4=nn.Linear(256,256)\n",
    "        self.linear5=nn.Linear(320,512)\n",
    "        self.linear6=nn.Linear(512,128)\n",
    "        self.linear7=nn.Linear(128,32)\n",
    "        self.linear8=nn.Linear(32,1)\n",
    "      \n",
    "\n",
    "    def forward(self, feature, id):\n",
    "        id=self.embedding(id).squeeze()\n",
    "        id=self.linear1(id).squeeze()\n",
    "        id=id*torch.sigmoid(id)\n",
    "        id=self.linear2(id).squeeze()\n",
    "        id=id*torch.sigmoid(id)\n",
    "        id=self.linear2(id).squeeze()\n",
    "        id=id*torch.sigmoid(id)\n",
    "\n",
    "\n",
    "        feature=self.linear3(feature).squeeze()\n",
    "        feature=feature*torch.sigmoid(feature)\n",
    "        feature=self.linear4(feature).squeeze()\n",
    "        feature=feature*torch.sigmoid(feature)\n",
    "        feature=self.linear4(feature).squeeze()\n",
    "        feature=feature*torch.sigmoid(feature)\n",
    "\n",
    "        x=torch.cat((id,feature),1).to(\"cuda\")\n",
    "        x=self.linear5(x).squeeze()\n",
    "        x=x*torch.sigmoid(x)\n",
    "        x=self.linear6(x).squeeze()\n",
    "        x=x*torch.sigmoid(x)\n",
    "\n",
    "        x=self.linear7(x).squeeze()\n",
    "        x=x*torch.sigmoid(x)\n",
    "\n",
    "        x=self.linear8(x).squeeze()\n",
    "        x=40*torch.sigmoid(x)-20\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "       # linear_result=self.act(self.linear2(linear_result))\n",
    "        #result=self.linear3(result)\n",
    "        #result=40*torch.sigmoid(result)-20\n",
    "        return x.squeeze()\n",
    "\n",
    "model1_1 = NeuralNetwork().to(\"cuda\")\n",
    "model1_1=model1_1.double()\n",
    "model1_2 = NeuralNetwork().to(\"cuda\")\n",
    "model1_2=model1_2.double()\n",
    "model1_3 = NeuralNetwork().to(\"cuda\")\n",
    "model1_3=model1_3.double()\n",
    "model1_4 = NeuralNetwork().to(\"cuda\")\n",
    "model1_4=model1_4.double()\n",
    "\n",
    "model2_1 = NeuralNetwork().to(\"cuda\")\n",
    "model2_1=model2_1.double()\n",
    "model2_2 = NeuralNetwork().to(\"cuda\")\n",
    "model2_2=model2_2.double()\n",
    "model2_3 = NeuralNetwork().to(\"cuda\")\n",
    "model2_3=model2_3.double()\n",
    "model2_4 = NeuralNetwork().to(\"cuda\")\n",
    "model2_4=model2_4.double()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "optimizer1_1 = torch.optim.Adam(model1_1.parameters(), lr=learning_rate,weight_decay=1e-5)\n",
    "optimizer1_2 = torch.optim.Adam(model1_2.parameters(), lr=learning_rate,weight_decay=1e-5)\n",
    "optimizer1_3 = torch.optim.Adam(model1_3.parameters(), lr=learning_rate,weight_decay=1e-5)\n",
    "optimizer1_4 = torch.optim.Adam(model1_4.parameters(), lr=learning_rate,weight_decay=1e-5)\n",
    "\n",
    "\n",
    "optimizer2_1 = torch.optim.Adam(model2_1.parameters(), lr=learning_rate,weight_decay=1e-5)\n",
    "optimizer2_2 = torch.optim.Adam(model2_2.parameters(), lr=learning_rate,weight_decay=1e-5)\n",
    "optimizer2_3 = torch.optim.Adam(model2_3.parameters(), lr=learning_rate,weight_decay=1e-5)\n",
    "optimizer2_4 = torch.optim.Adam(model2_4.parameters(), lr=learning_rate,weight_decay=1e-5)\n",
    "\n",
    "loss_fn1=torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPELoss(output, target):\n",
    "  return torch.mean(torch.abs((target - output) / target))    \n",
    "\n",
    "def RPDLoss(output, target):\n",
    "  return torch.mean(torch.abs(target - output) / ((torch.abs(target) + torch.abs(output)) / 2))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_1(dataloader, model, optimizer):\n",
    "    for  id,feature,y in tqdm(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(feature,id)\n",
    "        loss = loss_fn1(pred,y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "def train_2(dataloader, model, optimizer):\n",
    "    for id,feature, y in tqdm(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(feature,id)\n",
    "        loss = -torch.corrcoef(torch.stack((pred,y)))[0,1]\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "def train_3(dataloader, model, optimizer):\n",
    "    for id,feature, y in tqdm(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(feature,id)\n",
    "        loss = MAPELoss(pred,y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "def train_4(dataloader, model, optimizer):\n",
    "    for id,feature, y in tqdm(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(feature,id)\n",
    "        loss = RPDLoss(pred,y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader,model):\n",
    "    averagescore=0\n",
    "    i=0\n",
    "    for id, feature,y in dataloader:\n",
    "        i=i+1\n",
    "        pred=model(feature,id)\n",
    "        score=torch.corrcoef(torch.stack((pred,y)))[0,1]\n",
    "        averagescore+=score\n",
    "    averagescore/=i\n",
    "    return averagescore\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12272/12272 [01:29<00:00, 136.64it/s]\n",
      "100%|██████████| 12272/12272 [01:48<00:00, 112.87it/s]\n",
      "100%|██████████| 12272/12272 [01:29<00:00, 137.34it/s]\n",
      "100%|██████████| 12272/12272 [01:29<00:00, 137.67it/s]\n",
      "100%|██████████| 3068/3068 [00:54<00:00, 56.26it/s]\n",
      "100%|██████████| 3068/3068 [01:06<00:00, 45.80it/s]\n",
      "100%|██████████| 3068/3068 [00:54<00:00, 55.97it/s]\n",
      "100%|██████████| 3068/3068 [00:55<00:00, 55.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12272/12272 [01:26<00:00, 141.07it/s]\n",
      "100%|██████████| 12272/12272 [01:46<00:00, 115.43it/s]\n",
      "100%|██████████| 12272/12272 [01:28<00:00, 139.09it/s]\n",
      "100%|██████████| 12272/12272 [01:29<00:00, 137.75it/s]\n",
      "100%|██████████| 3068/3068 [00:53<00:00, 57.16it/s]\n",
      "100%|██████████| 3068/3068 [01:06<00:00, 46.23it/s]\n",
      "100%|██████████| 3068/3068 [00:54<00:00, 56.42it/s]\n",
      "100%|██████████| 3068/3068 [00:54<00:00, 55.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12272/12272 [01:27<00:00, 140.76it/s]\n",
      "100%|██████████| 12272/12272 [01:46<00:00, 115.55it/s]\n",
      "100%|██████████| 12272/12272 [01:27<00:00, 139.58it/s]\n",
      "100%|██████████| 12272/12272 [01:28<00:00, 138.24it/s]\n",
      "100%|██████████| 3068/3068 [00:53<00:00, 57.34it/s]\n",
      "100%|██████████| 3068/3068 [01:06<00:00, 46.20it/s]\n",
      "100%|██████████| 3068/3068 [00:53<00:00, 57.39it/s]\n",
      "100%|██████████| 3068/3068 [00:53<00:00, 57.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12272/12272 [01:26<00:00, 141.13it/s]\n",
      "100%|██████████| 12272/12272 [01:45<00:00, 115.95it/s]\n",
      "100%|██████████| 12272/12272 [01:30<00:00, 135.60it/s]\n",
      "100%|██████████| 12272/12272 [01:24<00:00, 144.91it/s]\n",
      "100%|██████████| 3068/3068 [00:47<00:00, 64.35it/s]\n",
      "100%|██████████| 3068/3068 [00:55<00:00, 55.00it/s]\n",
      "100%|██████████| 3068/3068 [00:48<00:00, 63.31it/s]\n",
      "100%|██████████| 3068/3068 [00:48<00:00, 63.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12272/12272 [01:21<00:00, 150.62it/s]\n",
      "100%|██████████| 12272/12272 [01:35<00:00, 128.15it/s]\n",
      "100%|██████████| 12272/12272 [01:22<00:00, 148.87it/s]\n",
      "100%|██████████| 12272/12272 [01:23<00:00, 147.82it/s]\n",
      "100%|██████████| 3068/3068 [00:47<00:00, 64.16it/s]\n",
      "100%|██████████| 3068/3068 [00:56<00:00, 54.56it/s]\n",
      "100%|██████████| 3068/3068 [00:48<00:00, 63.49it/s]\n",
      "100%|██████████| 3068/3068 [00:48<00:00, 63.23it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"epoch{}/{}\".format(i+1,5))\n",
    "    train_1(DataLoader1,model1_1,optimizer1_1)\n",
    "    train_2(DataLoader1,model1_2,optimizer1_2)\n",
    "    train_3(DataLoader1,model1_3,optimizer1_3)\n",
    "    train_4(DataLoader1,model1_4,optimizer1_4)\n",
    "\n",
    "    train_1(DataLoader2,model2_1,optimizer2_1)\n",
    "    train_2(DataLoader2,model2_2,optimizer2_2)\n",
    "    train_3(DataLoader2,model2_3,optimizer2_3)\n",
    "    train_4(DataLoader2,model2_4,optimizer2_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model1_1, 'tensorflow model/model1_1.pth')\n",
    "torch.save(model1_2, 'tensorflow model/model1_2.pth')\n",
    "torch.save(model1_3, 'tensorflow model/model1_3.pth')\n",
    "torch.save(model1_4, 'tensorflow model/model1_4.pth')\n",
    "\n",
    "torch.save(model2_1, 'tensorflow model/model2_1.pth')\n",
    "torch.save(model2_2, 'tensorflow model/model2_2.pth')\n",
    "torch.save(model2_3, 'tensorflow model/model2_3.pth')\n",
    "torch.save(model2_4, 'tensorflow model/model2_4.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_1 = NeuralNetwork().to(\"cuda\")\n",
    "model1_1=model1_1.double()\n",
    "model1_2 = NeuralNetwork().to(\"cuda\")\n",
    "model1_2=model1_2.double()\n",
    "\n",
    "model2_1 = NeuralNetwork().to(\"cuda\")\n",
    "model2_1=model2_1.double()\n",
    "model2_2 = NeuralNetwork().to(\"cuda\")\n",
    "model2_2=model2_2.double()\n",
    "\n",
    "\n",
    "model3_1 = NeuralNetwork().to(\"cuda\")\n",
    "model3_1=model3_1.double()\n",
    "model3_2 = NeuralNetwork().to(\"cuda\")\n",
    "model3_2=model3_2.double()\n",
    "\n",
    "\n",
    "model1_1=torch.load('tensorflow model/model1_1.pth')\n",
    "model1_2=torch.load('tensorflow model/model1_2.pth')\n",
    "model2_1=torch.load('tensorflow model/model2_1.pth')\n",
    "model2_2=torch.load('tensorflow model/model2_2.pth')\n",
    "model3_1=torch.load('tensorflow model/model3_1.pth')\n",
    "model3_2=torch.load('tensorflow model/model3_2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 16.00 GiB total capacity; 14.35 GiB already allocated; 0 bytes free; 14.38 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8300\\1751931138.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataLoader1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel1_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8300\\3767827121.py\u001b[0m in \u001b[0;36mtest\u001b[1;34m(dataloader, model)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mpred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mscore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorrcoef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0maveragescore\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\qml\\Desktop\\学习\\reinforcement learning for Fintech\\Ubiquant Market Prediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8300\\3230301353.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, feature, id)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear6\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\qml\\Desktop\\学习\\reinforcement learning for Fintech\\Ubiquant Market Prediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\qml\\Desktop\\学习\\reinforcement learning for Fintech\\Ubiquant Market Prediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\qml\\Desktop\\学习\\reinforcement learning for Fintech\\Ubiquant Market Prediction\\venv\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 16.00 GiB total capacity; 14.35 GiB already allocated; 0 bytes free; 14.38 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "test(DataLoader1,model1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.60609153],\n",
       "       [-0.60609153],\n",
       "       [ 0.80812204],\n",
       "       [-0.60609153],\n",
       "       [-0.60609153],\n",
       "       [ 2.2223356 ],\n",
       "       [-0.60609153]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " pca.fit_transform(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8d54f9552fa829e297b1fedb11353f4eeb32c8a885e3418c0be5f50c074ccfc7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
