{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\qml\\\\Desktop\\\\学习\\\\reinforcement learning for Fintech\\\\Ubiquant Market Prediction\\\\train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurenamelist=list(np.load(r'C:\\Users\\qml\\Desktop\\学习\\reinforcement learning for Fintech\\Ubiquant Market Prediction\\dropout+normrlbatch+250feature\\featurename.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = df[featurenamelist]\n",
    "y = df[\"target\"]\n",
    "id=df[\"investment_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "feature=torch.from_numpy(feature.values)\n",
    "id=torch.from_numpy(id.values)\n",
    "y=torch.from_numpy(y.values)\n",
    "class FinData(Dataset):\n",
    "    def __init__(self,feature,id,y):\n",
    "        self.feature = feature.squeeze().to(\"cuda\")\n",
    "        self.y = y.squeeze().to(\"cuda\")\n",
    "        self.id = id.squeeze().to(torch.int64).to(\"cuda\")\n",
    "        self.len = len(y)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return self.id[idx],self.feature[idx],self.y[idx]\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "Dataset_train=FinData(feature=feature,id=id,y=y)\n",
    "DataLoader1=DataLoader(Dataset_train,batch_size=128,shuffle=True)\n",
    "DataLoader2=DataLoader(Dataset_train,batch_size=1024,shuffle=True)\n",
    "DataLoader3=DataLoader(Dataset_train,batch_size=512,shuffle=True)\n",
    "DataLoader4=DataLoader(Dataset_train,batch_size=256,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.embedding=nn.Embedding(4000,32)\n",
    "        self.linear1=nn.Linear(32,64)\n",
    "        self.linear2=nn.Linear(64,64)\n",
    "        self.linear3=nn.Linear(250,256)\n",
    "        self.linear4=nn.Linear(256,256)\n",
    "        self.linear5=nn.Linear(320,512)\n",
    "        self.linear6=nn.Linear(512,128)\n",
    "        self.linear7=nn.Linear(128,32)\n",
    "        self.linear8=nn.Linear(32,1)\n",
    "        self.linear9=nn.Linear(32,2)\n",
    "        self.dropout=nn.Dropout(p=0.1)\n",
    "      \n",
    "\n",
    "    def forward(self, feature, id):\n",
    "        id=self.embedding(id).squeeze()\n",
    "        id=self.linear1(id).squeeze()\n",
    "        id=self.dropout(id)\n",
    "        id=id*torch.sigmoid(id)\n",
    "        id=self.linear2(id).squeeze()\n",
    "        id=id*torch.sigmoid(id)\n",
    "        id=self.linear2(id).squeeze()\n",
    "        id=id*torch.sigmoid(id)\n",
    "\n",
    "\n",
    "        feature=self.linear3(feature).squeeze()\n",
    "        feature=self.dropout(feature)\n",
    "        feature=feature*torch.sigmoid(feature)\n",
    "        feature=self.linear4(feature).squeeze()\n",
    "        feature=feature*torch.sigmoid(feature)\n",
    "        feature=self.linear4(feature).squeeze()\n",
    "        feature=feature*torch.sigmoid(feature)\n",
    "\n",
    "        x_all=torch.cat((id,feature),1)\n",
    "        x=self.linear5(x_all).squeeze()\n",
    "        x=x*torch.sigmoid(x)\n",
    "        x=self.linear6(x).squeeze()\n",
    "        x=x*torch.sigmoid(x)\n",
    "\n",
    "        x=self.linear7(x).squeeze()\n",
    "        x=x*torch.sigmoid(x)\n",
    "\n",
    "        x=self.linear8(x).squeeze()\n",
    "        x=20*torch.sigmoid(x)\n",
    "\n",
    "\n",
    "        x2=self.linear5(x_all).squeeze()\n",
    "        x2=x2*torch.sigmoid(x2)\n",
    "\n",
    "        x2=self.linear6(x2).squeeze()\n",
    "        x2=x2*torch.sigmoid(x2)\n",
    "\n",
    "        x2=self.linear7(x2).squeeze()\n",
    "        x2=x2*torch.sigmoid(x2)\n",
    "\n",
    "        x2=self.linear9(x2).squeeze()\n",
    "        x2=torch.sigmoid(x2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        return x.squeeze(),x2.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_1 = NeuralNetwork().to(\"cuda\")\n",
    "model1_1=model1_1.double()\n",
    "model1_2 = NeuralNetwork().to(\"cuda\")\n",
    "model1_2=model1_2.double()\n",
    "\n",
    "model2_1 = NeuralNetwork().to(\"cuda\")\n",
    "model2_1=model2_1.double()\n",
    "model2_2 = NeuralNetwork().to(\"cuda\")\n",
    "model2_2=model2_2.double()\n",
    "\n",
    "\n",
    "model3_1 = NeuralNetwork().to(\"cuda\")\n",
    "model3_1=model3_1.double()\n",
    "model3_2 = NeuralNetwork().to(\"cuda\")\n",
    "model3_2=model3_2.double()\n",
    "\n",
    "model4_1 = NeuralNetwork().to(\"cuda\")\n",
    "model4_1=model4_1.double()\n",
    "model4_2 = NeuralNetwork().to(\"cuda\")\n",
    "model4_2=model4_2.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_1=torch.load('model1_1.pth')\n",
    "model1_2=torch.load('model1_2.pth')\n",
    "model2_1=torch.load('model2_1.pth')\n",
    "model2_2=torch.load('model2_2.pth')\n",
    "model3_1=torch.load('model3_1.pth')\n",
    "model3_2=torch.load('model3_2.pth')\n",
    "model4_1=torch.load('model4_1.pth')\n",
    "model4_2=torch.load('model4_2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "optimizer1_1 = torch.optim.Adam(model1_1.parameters(), lr=learning_rate,weight_decay=1e-5)\n",
    "optimizer1_2 = torch.optim.Adam(model1_2.parameters(), lr=learning_rate,weight_decay=1e-5)\n",
    "optimizer2_1 = torch.optim.Adam(model2_1.parameters(), lr=learning_rate,weight_decay=1e-5)\n",
    "optimizer2_2 = torch.optim.Adam(model2_2.parameters(), lr=learning_rate,weight_decay=1e-5)\n",
    "optimizer3_1 = torch.optim.Adam(model3_1.parameters(), lr=learning_rate,weight_decay=1e-5)\n",
    "optimizer3_2 = torch.optim.Adam(model3_2.parameters(), lr=learning_rate,weight_decay=1e-5)\n",
    "optimizer4_1 = torch.optim.Adam(model4_1.parameters(), lr=learning_rate,weight_decay=1e-5)\n",
    "optimizer4_2 = torch.optim.Adam(model4_2.parameters(), lr=learning_rate,weight_decay=1e-5)\n",
    "loss_fn1=torch.nn.MSELoss()\n",
    "loss_fn2=torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_1(dataloader, model, optimizer):\n",
    "    for  id,feature,y in tqdm(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred,label = model(feature,id)\n",
    "        loss1 = loss_fn1(pred,torch.abs(y))\n",
    "        loss2 = loss_fn2(label,(0.5*(y/torch.abs(y)+torch.tensor([1]).to(device))).long().to(\"cuda\"))\n",
    "        # Backpropagation\n",
    "        loss = loss1+0.05*loss2\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "def train_2(dataloader, model, optimizer):\n",
    "    for id,feature, y in tqdm(dataloader):\n",
    "        pred,label = model(feature,id)\n",
    "        loss1 = -torch.corrcoef(torch.stack((pred,torch.abs(y))))[0,1]\n",
    "        loss2 = loss_fn2(label,(0.5*(y/torch.abs(y)+torch.tensor([1]).to(device))).long().to(\"cuda\"))\n",
    "        # Backpropagation\n",
    "        loss = loss1+0.05*loss2\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        # Compute prediction and loss\n",
    "        # pred = model(feature,id)\n",
    "        # loss = -torch.corrcoef(torch.stack((pred,y)))[0,1]\n",
    "        # # Backpropagation\n",
    "        # optimizer.zero_grad()\n",
    "        # loss.backward()\n",
    "        # optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader):\n",
    "    score=0\n",
    "    number=0\n",
    "    for id, feature,y in tqdm(dataloader):\n",
    "        number+=1\n",
    "        with torch.no_grad():\n",
    "            pred,label=model(feature,id)\n",
    "            cats=[]\n",
    "            for cat in label:\n",
    "                if cat[0]>cat[1]:\n",
    "                    cats.append(-1)\n",
    "                else:\n",
    "                    cats.append(1)\n",
    "            cats=torch.tensor(cats).to(device)\n",
    "            pred=pred*cats\n",
    "            score+=torch.corrcoef(torch.stack((pred,y)))[0,1].item()\n",
    "    score=score/number\n",
    "    print(score)            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24543/24543 [03:14<00:00, 126.39it/s]\n",
      "100%|██████████| 24543/24543 [03:32<00:00, 115.75it/s]\n",
      "100%|██████████| 3068/3068 [01:14<00:00, 41.13it/s]\n",
      "100%|██████████| 3068/3068 [01:17<00:00, 39.64it/s]\n",
      "100%|██████████| 6136/6136 [01:28<00:00, 68.97it/s]\n",
      "100%|██████████| 6136/6136 [01:36<00:00, 63.69it/s]\n",
      "100%|██████████| 12272/12272 [02:04<00:00, 98.65it/s] \n",
      "100%|██████████| 12272/12272 [02:07<00:00, 96.36it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24543/24543 [03:12<00:00, 127.37it/s]\n",
      "100%|██████████| 24543/24543 [03:26<00:00, 118.59it/s]\n",
      "100%|██████████| 3068/3068 [01:09<00:00, 43.86it/s]\n",
      "100%|██████████| 3068/3068 [01:11<00:00, 42.78it/s]\n",
      "100%|██████████| 6136/6136 [01:20<00:00, 76.52it/s]\n",
      "100%|██████████| 6136/6136 [01:32<00:00, 66.34it/s]\n",
      "100%|██████████| 12272/12272 [02:03<00:00, 99.45it/s] \n",
      "100%|██████████| 12272/12272 [02:16<00:00, 89.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24543/24543 [03:12<00:00, 127.75it/s]\n",
      "100%|██████████| 24543/24543 [03:32<00:00, 115.52it/s]\n",
      "100%|██████████| 3068/3068 [01:14<00:00, 41.43it/s]\n",
      "100%|██████████| 3068/3068 [01:17<00:00, 39.82it/s]\n",
      "100%|██████████| 6136/6136 [01:25<00:00, 71.61it/s]\n",
      "100%|██████████| 6136/6136 [01:31<00:00, 66.97it/s]\n",
      "100%|██████████| 12272/12272 [02:01<00:00, 100.64it/s]\n",
      "100%|██████████| 12272/12272 [02:12<00:00, 92.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24543/24543 [03:11<00:00, 128.27it/s]\n",
      "100%|██████████| 24543/24543 [03:32<00:00, 115.54it/s]\n",
      "100%|██████████| 3068/3068 [01:13<00:00, 41.49it/s]\n",
      "100%|██████████| 3068/3068 [01:17<00:00, 39.73it/s]\n",
      "100%|██████████| 6136/6136 [01:25<00:00, 71.68it/s]\n",
      "100%|██████████| 6136/6136 [01:31<00:00, 66.85it/s]\n",
      "100%|██████████| 12272/12272 [02:01<00:00, 100.81it/s]\n",
      "100%|██████████| 12272/12272 [02:13<00:00, 92.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24543/24543 [03:06<00:00, 131.62it/s]\n",
      "100%|██████████| 24543/24543 [03:27<00:00, 118.45it/s]\n",
      "100%|██████████| 3068/3068 [01:12<00:00, 42.26it/s]\n",
      "100%|██████████| 3068/3068 [01:15<00:00, 40.56it/s]\n",
      "100%|██████████| 6136/6136 [01:24<00:00, 72.59it/s]\n",
      "100%|██████████| 6136/6136 [01:29<00:00, 68.37it/s]\n",
      "100%|██████████| 12272/12272 [01:59<00:00, 102.36it/s]\n",
      "100%|██████████| 12272/12272 [02:10<00:00, 94.14it/s]\n",
      "100%|██████████| 3068/3068 [03:21<00:00, 15.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06363341676028413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3068/3068 [03:21<00:00, 15.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05959566367771941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2060/3068 [02:15<01:06, 15.18it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2020\\206559794.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel1_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDataLoader2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel1_2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDataLoader2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel2_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDataLoader2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel2_2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDataLoader2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel3_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDataLoader2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2020\\2670077548.py\u001b[0m in \u001b[0;36mtest\u001b[1;34m(model, dataloader)\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mcats\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcat\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mcat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m                     \u001b[0mcats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "number_epoch=20\n",
    "for i in range(number_epoch):\n",
    "    print(\"epoch{}/{}\".format(i+1,number_epoch))\n",
    "    train_1(DataLoader1,model1_1,optimizer1_1)\n",
    "    train_2(DataLoader1,model1_2,optimizer1_2)\n",
    "\n",
    "\n",
    "    train_1(DataLoader2,model2_1,optimizer2_1)\n",
    "    train_2(DataLoader2,model2_2,optimizer2_2)\n",
    "\n",
    "\n",
    "    train_1(DataLoader3,model3_1,optimizer3_1)\n",
    "    train_2(DataLoader3,model3_2,optimizer3_2)\n",
    "\n",
    "\n",
    "    train_1(DataLoader4,model4_1,optimizer4_1)\n",
    "    train_2(DataLoader4,model4_2,optimizer4_2)\n",
    "\n",
    "    if (i+1)%5==0:\n",
    "        test(model1_1,DataLoader2)\n",
    "        test(model1_2,DataLoader2)\n",
    "        test(model2_1,DataLoader2)\n",
    "        test(model2_2,DataLoader2)\n",
    "        test(model3_1,DataLoader2)\n",
    "        test(model3_2,DataLoader2)\n",
    "        test(model4_1,DataLoader2)\n",
    "        test(model4_2,DataLoader2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model1_1, 'model1_1.pth')\n",
    "torch.save(model1_2, 'model1_2.pth')\n",
    "torch.save(model2_1, 'model2_1.pth')\n",
    "torch.save(model2_2, 'model2_2.pth')\n",
    "torch.save(model3_1, 'model3_1.pth')\n",
    "torch.save(model3_2, 'model3_2.pth')\n",
    "torch.save(model4_1, 'model4_1.pth')\n",
    "torch.save(model4_2, 'model4_2.pth')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8d54f9552fa829e297b1fedb11353f4eeb32c8a885e3418c0be5f50c074ccfc7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
